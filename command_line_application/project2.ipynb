{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpRoNnwUOxR4",
        "outputId": "9a0e7275-e5c4-4919-95eb-cbd9a610e14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2P_R9axO2E6",
        "outputId": "ca3dd71b-9c97-4695-fc47-3dbd96115052"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/aipnd-project-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOQoSibtPQoh",
        "outputId": "2eadf4ef-a9f3-4365-c11c-0fbbb8a81076"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/aipnd-project-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVskPV1RPSwU",
        "outputId": "b16e598c-01eb-4f15-e4a0-26b9fabaed19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.12.0\n",
            "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.11.0\n",
            "  Downloading torchaudio-0.11.0-cp310-cp310-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2024.2.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu121\n",
            "    Uninstalling torchaudio-2.1.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0 torchaudio-0.11.0 torchvision-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5gNVeAUPVBZ",
        "outputId": "95d6cfd1-28a3-4ebb-effa-08806a5139f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu102\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py /content/drive/MyDrive/aipnd-project-master/flower_data --epochs 3 --gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9e21Er7Pcf2",
        "outputId": "95bca6c6-5232-4bcd-8067-5c8df58e94a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Setting up model architecture...\n",
            "Training model...\n",
            "Epoch: 1/3...  Training Loss: 4.6014 Validation Loss 0.3480 Validation Accuracy: 0.0369\n",
            "Epoch: 1/3...  Training Loss: 4.5284 Validation Loss 0.3407 Validation Accuracy: 0.0824\n",
            "Epoch: 1/3...  Training Loss: 4.4046 Validation Loss 0.3241 Validation Accuracy: 0.1129\n",
            "Epoch: 1/3...  Training Loss: 4.2026 Validation Loss 0.3164 Validation Accuracy: 0.1270\n",
            "Epoch: 1/3...  Training Loss: 4.2072 Validation Loss 0.3058 Validation Accuracy: 0.1562\n",
            "Epoch: 1/3...  Training Loss: 3.8805 Validation Loss 0.3104 Validation Accuracy: 0.2051\n",
            "Epoch: 1/3...  Training Loss: 3.6969 Validation Loss 0.2715 Validation Accuracy: 0.2113\n",
            "Epoch: 1/3...  Training Loss: 3.5299 Validation Loss 0.2470 Validation Accuracy: 0.2540\n",
            "Epoch: 1/3...  Training Loss: 3.4738 Validation Loss 0.2235 Validation Accuracy: 0.2818\n",
            "Epoch: 1/3...  Training Loss: 3.1515 Validation Loss 0.2334 Validation Accuracy: 0.3290\n",
            "Epoch: 1/3...  Training Loss: 3.1513 Validation Loss 0.1884 Validation Accuracy: 0.3737\n",
            "Epoch: 1/3...  Training Loss: 2.8412 Validation Loss 0.2154 Validation Accuracy: 0.3799\n",
            "Epoch: 1/3...  Training Loss: 2.8068 Validation Loss 0.1616 Validation Accuracy: 0.4478\n",
            "Epoch: 1/3...  Training Loss: 2.7015 Validation Loss 0.1677 Validation Accuracy: 0.4615\n",
            "Epoch: 1/3...  Training Loss: 2.6026 Validation Loss 0.1411 Validation Accuracy: 0.4698\n",
            "Epoch: 1/3...  Training Loss: 2.3608 Validation Loss 0.1464 Validation Accuracy: 0.4880\n",
            "Epoch: 1/3...  Training Loss: 2.2991 Validation Loss 0.1187 Validation Accuracy: 0.5128\n",
            "Epoch: 2/3...  Training Loss: 1.8500 Validation Loss 0.1687 Validation Accuracy: 0.5213\n",
            "Epoch: 2/3...  Training Loss: 1.9958 Validation Loss 0.1320 Validation Accuracy: 0.5349\n",
            "Epoch: 2/3...  Training Loss: 1.9939 Validation Loss 0.1420 Validation Accuracy: 0.5730\n",
            "Epoch: 2/3...  Training Loss: 1.8397 Validation Loss 0.1520 Validation Accuracy: 0.5756\n",
            "Epoch: 2/3...  Training Loss: 1.8823 Validation Loss 0.1190 Validation Accuracy: 0.5776\n",
            "Epoch: 2/3...  Training Loss: 1.8384 Validation Loss 0.1016 Validation Accuracy: 0.6045\n",
            "Epoch: 2/3...  Training Loss: 2.0257 Validation Loss 0.1129 Validation Accuracy: 0.6059\n",
            "Epoch: 2/3...  Training Loss: 1.7071 Validation Loss 0.1356 Validation Accuracy: 0.6138\n",
            "Epoch: 2/3...  Training Loss: 1.6348 Validation Loss 0.0945 Validation Accuracy: 0.6232\n",
            "Epoch: 2/3...  Training Loss: 1.7793 Validation Loss 0.0873 Validation Accuracy: 0.6007\n",
            "Epoch: 2/3...  Training Loss: 1.8534 Validation Loss 0.1328 Validation Accuracy: 0.6286\n",
            "Epoch: 2/3...  Training Loss: 1.6987 Validation Loss 0.1129 Validation Accuracy: 0.6435\n",
            "Epoch: 2/3...  Training Loss: 1.5379 Validation Loss 0.1154 Validation Accuracy: 0.6487\n",
            "Epoch: 2/3...  Training Loss: 1.5818 Validation Loss 0.1099 Validation Accuracy: 0.6663\n",
            "Epoch: 2/3...  Training Loss: 1.5652 Validation Loss 0.1110 Validation Accuracy: 0.6300\n",
            "Epoch: 2/3...  Training Loss: 1.5302 Validation Loss 0.1048 Validation Accuracy: 0.6744\n",
            "Epoch: 2/3...  Training Loss: 1.5370 Validation Loss 0.0797 Validation Accuracy: 0.6788\n",
            "Epoch: 3/3...  Training Loss: 0.9088 Validation Loss 0.1143 Validation Accuracy: 0.6283\n",
            "Epoch: 3/3...  Training Loss: 1.4452 Validation Loss 0.0547 Validation Accuracy: 0.7000\n",
            "Epoch: 3/3...  Training Loss: 1.3411 Validation Loss 0.0751 Validation Accuracy: 0.6967\n",
            "Epoch: 3/3...  Training Loss: 1.3402 Validation Loss 0.1210 Validation Accuracy: 0.6880\n",
            "Epoch: 3/3...  Training Loss: 1.4093 Validation Loss 0.0619 Validation Accuracy: 0.6939\n",
            "Epoch: 3/3...  Training Loss: 1.2943 Validation Loss 0.0762 Validation Accuracy: 0.7000\n",
            "Epoch: 3/3...  Training Loss: 1.3535 Validation Loss 0.0820 Validation Accuracy: 0.6890\n",
            "Epoch: 3/3...  Training Loss: 1.2836 Validation Loss 0.0701 Validation Accuracy: 0.7424\n",
            "Epoch: 3/3...  Training Loss: 1.3167 Validation Loss 0.0783 Validation Accuracy: 0.7137\n",
            "Epoch: 3/3...  Training Loss: 1.1654 Validation Loss 0.0713 Validation Accuracy: 0.7451\n",
            "Epoch: 3/3...  Training Loss: 1.4023 Validation Loss 0.1013 Validation Accuracy: 0.6952\n",
            "Epoch: 3/3...  Training Loss: 1.1524 Validation Loss 0.1016 Validation Accuracy: 0.7247\n",
            "Epoch: 3/3...  Training Loss: 1.2418 Validation Loss 0.0897 Validation Accuracy: 0.7226\n",
            "Epoch: 3/3...  Training Loss: 1.2480 Validation Loss 0.0733 Validation Accuracy: 0.7269\n",
            "Epoch: 3/3...  Training Loss: 1.2869 Validation Loss 0.0851 Validation Accuracy: 0.7149\n",
            "Epoch: 3/3...  Training Loss: 1.2927 Validation Loss 0.0754 Validation Accuracy: 0.7187\n",
            "Epoch: 3/3...  Training Loss: 1.2630 Validation Loss 0.0658 Validation Accuracy: 0.7305\n",
            "Validating testing accuracy...\n",
            "Accuracy of the network on test images: 73.82164597511292%\n",
            "Saving model to disk...\n",
            "COMPLETED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py /content/drive/MyDrive/aipnd-project-master/flower_data/test/1/image_06752.jpg checkpoint.pth --top_k 5 --category_names /content/drive/MyDrive/aipnd-project-master/cat_to_name.json --gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GXW520iQ-2L",
        "outputId": "3a3ba77e-f2f2-489c-80df-43d149d6e589"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets\n",
            "Loading pre-trained model\n",
            "Running inference\n",
            "Outputting results\n",
            "xxxxxxxxxxxxxxxxxxxxx\n",
            "spring crocus with a probability of 33.86141061782837%\n",
            "pink primrose with a probability of 18.483194708824158%\n",
            "passion flower with a probability of 9.759214520454407%\n",
            "spear thistle with a probability of 7.235784083604813%\n",
            "cyclamen with a probability of 5.40471225976944%\n",
            "-xxxxxxxxxxxxxx-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gxObcsXgb6zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhZ7ZRG0b8Jo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}